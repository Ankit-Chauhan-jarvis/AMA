[
    {
        "speaker": "SPEAKER_03",
        "start": 3.8400000000000043,
        "end": 86.2,
        "text": "Okay, we're live. Hello, everyone. Welcome to the Editor Extensions group meeting. It's December 7th. The first part here is an announcement from my side. So I've been asked what I think about hosting an intern in our team next summer, intern or interns. I personally, when I was in IC, I really enjoyed mentoring interns back then. So I am excited by the idea. But in my experience, a big key to success for this is to make sure that there is like a clear and dedicated support for interns from like engineers on the team, like specifically like a engineer to one engineer to one intern kind of like mapping, you know, and that means that includes, you know, identifying the project to be done, training the intern on their tech skills, coaching, all of that. So if you are interested in mentoring an intern, please reach out to me, ideally today, just so I can let Darva know that there if there is interest or not in the team. This would be next summer. Yeah, next summer. I said that. Yeah. And I think it's like a couple months. And there are the program ran last year. So there's a lot of structure. Actually, I put a few links here to like the different issues like onboarding stuff, common concerns and how they're addressed and things like that. So there's there's quite some. Some stuff there as well. Yeah, there's some comments here. Aaron, do you want to do you want to verbalize?"
    },
    {
        "speaker": "SPEAKER_01",
        "start": 87.07999999999998,
        "end": 123.28,
        "text": "Yeah, for sure. Well, in a previous role, I got to mentor like like half the interns sort of yearly, like all those sort of back under front end interns that you get to sort of speak with. There's loads of UX interns and stuff in the previous role as well and product management interns. I love that. So in the Belfast office, we sort of had like up to like 12 interns sort of initially. And then I was 12. And I was 12 to 15 and 20. And it increased from 20 even since I've left. And I really thought that program was great. It's really, really a good way to get in a bunch of junior engineers. There was a bigger to learn and happy to jump on board and learn stuff."
    },
    {
        "speaker": "SPEAKER_03",
        "start": 125.76,
        "end": 192.8,
        "text": "Nice. Awesome. Yeah .daughter was a time I remember at a job where I had at some point I had three interns in parallel assigned to me and they were in. Hello, the other guy. And we one of them was in second year, one in third year and one fourth year of college. And the one in second year was actually the most the most productive one that kind of blew it out of the water. So that was kind of an interesting experience as well. Anyway. All right. Sweet. So, yeah, I'll then I'll nominate at least Aaron or let Darwin know Aaron. It sounds like you're interested. Other folks here just like, yeah, John, you're saying you also have experience and enjoyed it. Let me know if you're actually interested to do it here. Yeah. Okay. Cool. All right. Awesome. And Dylan is also plus one for instant and slight, slight recency bias here, obviously. And of course, similarity, but I don't know. The boats. Cool. Next up here, Aaron, you want to do the honors of the next announcement?"
    },
    {
        "speaker": "SPEAKER_01",
        "start": 192.98,
        "end": 210.06,
        "text": "Yeah, for sure. And so I've become a language server maintainer, I guess, over the weekend and sort of what's one of the pushes to coach Josh. So I've been doing a lot of discussions. There was sort of a lack of maintainers available and because I was already in the area anyways, I got moved from a reviewer to maintainer. So yeah, if anybody needs reviews, I'm happy to help now."
    },
    {
        "speaker": "SPEAKER_03",
        "start": 212.02,
        "end": 331.74,
        "text": "Awesome. Yes. Very happy about this. Yeah. And the process for becoming language server maintainer is extremely lean. So we were able to quick turn around there as well. Yeah. Nothing like the monoliths really. All right. Sweet. Next one. Yeah. Discussion. So yeah, I wanted to touch a little bit about, you know, talk a bit about the, the latency or I guess it's not really just latency at this point, but the, the, the, the whole kind of sprint crunch stuff that's going on this week on code suggestions. So I think the main open extensions topics still are the language server cache. We have tree sitter for VS code as well. And then there's a formatting on jet brains that, that Ali had in had started as well. So I just wanted to mention. Yeah. For anyone that doesn't have ongoing assignments related to any of this, like please contribute. The one thing I'd like people to contribute most to is to test the cache and VS code. Like just like try it out, leave feedback on that issue. Also, if it just works, just leave feedback that it works. That also kind of helped gain confidence that things work. Yeah. So thank you for that. Another point is like, this has been a long and stressful week. Some for some folks weeks because. Some people did work over the weekend. So I want to remind everyone to like, you know, take breaks and to reach out to me if you're feeling overwhelmed as well, because this is not normal circumstances. I had this morning off for like an embassy appointment, which was something long plan. And I did it. It was nice to walk in the snow outside and breathe fresh air. So encourage everyone to walk wherever you are. Yeah. Aaron, you have the next point here. New of him. Also pulled in the latest language. I mentioned. Awesome. Thank you for that. Yeah. Oh yeah. I guess John is also the thing. Like, I don't know. I haven't kept mine. I kept this in check, but it's good to make sure that whatever the latest is in the language of it still works with visual studio. That'd be great as well. Yeah."
    },
    {
        "speaker": "SPEAKER_02",
        "start": 332.66,
        "end": 339.28,
        "text": "Yeah. It's a quick thing there. I have, I have pulled in the latest language or a version and have tested, so we're, we're good on visual studio as well."
    },
    {
        "speaker": "SPEAKER_01",
        "start": 339.56,
        "end": 371.68,
        "text": "Awesome. Cool. Yeah. And so yeah, John, John and I had a pretty productive discussion around like automation. We could potentially do for visitor studio as well. Because right now, the diversity is pulling in the, like the windows binary. So I think we've got a package, Jason, so we can get renovated to automate the merge requests. That would be really quick. So that way John doesn't have to go and manually do all the steps. John can just sort of sign off after doing sort of some manual testing and then eventually other team members. Once we know what the sort of steps are to do that task for visual studio, we can jump on, do the same. I'm assuming we have windows environments, which I don't."
    },
    {
        "speaker": "SPEAKER_02",
        "start": 374.24,
        "end": 379.4,
        "text": "Aaron, I'll, I'll reach out to you. I'd love to have a little sync call right now. I'll call real quick to make sure that we're on the same, same, same page."
    },
    {
        "speaker": "SPEAKER_04",
        "start": 383.52,
        "end": 394.22,
        "text": "Yeah, sounds good. All right. Awesome. Um, yeah,"
    },
    {
        "speaker": "SPEAKER_03",
        "start": 394.3,
        "end": 542.8,
        "text": "so again, thank you everyone who's been contributing to this, um, so far, and it looks like we have also made really good progress today on the cash. So kind of looking forward to this one as well. Um, all right. The next, next point here. So, okay. The next one, I didn't write much here. I just wrote language server in jet brains. Um, because with this week, basically we've also kind of been adding, so I feel like this week has also stolen the thunder a bit about, you know, you know, us getting the language server in VS code because that happened like on Friday last week. And I was like, yes, finally we have it, you know, it's great. And then, and then now all of this and like, we didn't really have the time to pause and really, you know, be like, hooray. Like they did it. Like the language. We serve in VS code. Um, but we did and it's awesome. And I think everyone now is convinced that it is awesome and there's more and more stuff going in there. And so I've been thinking, yeah, I've been thinking more about this and I think if, uh, I think on the gender inside, there is kind of still work, like there's work to be done in terms of this week's effort. Um, but I feel like on visual studio, for example, there isn't too much. So I was wondering like, if I should like, I don't know. Yeah. I think it's a good idea to ask John to just start spiking this real quick or something, or like, kind of like look for options, dig a little bit more. Um, because I feel like we could, we could use this sooner rather than later. Um, yeah, so that's kind of like, just want to put this out there basically, um, similar approach to what we have in visual studio. Right. So, um, do it ourselves kind of approach rather than rely on the, on the ID provided, um, support because we can't do that. Uh, it's behind, uh, the paid it's for the paid editions of jet brains. Only. So yeah, cool. Uh, yeah. John sounds like you're happy to do that. I mean, we also have our one -on -one after this, we can discuss a bit more, see what, what, what, what could be a reasonable first stab at this. Um, yeah. Cool. All right. So yeah, this is a little bit me. Like I feel like this. Yeah. Again, to be, to be. To be transparent, like this week has kind of thrown all the plans and parties a little bit up in the air and then they let it again somewhere else. So I'm like, Hey, if we're throwing priorities in the air, I might as well throw this one also a little bit and see where it lands. So it's kind of like guerrilla, um, guerrilla prioritization a little bit. Cool. Uh, Aaron, you have the next point."
    },
    {
        "speaker": "SPEAKER_01",
        "start": 544.92,
        "end": 659.9,
        "text": "Yeah, for sure. Uh, so essentially one, one of the things that came up this morning is we, we, uh, got through a review. We merged in changes for a language. So we had a language server caching. And so, uh, some after caching, there was some sort of, uh, we weren't doing telemetry quite yet. So we had disabled it and then we enabled it with a new field for tracking. And that field that we added was a breaking change. Um, and there's like a local copy of the schema file. And so we, uh, we, uh, a contributor came in, added in the changes to, uh, to that file, which were the correct changes, but it had to happen in an upstream revolts rain because it didn't. We, if we release a language server, we would have been. And sending events that could have broke. Um, so I've gone ahead and tested with the latest language over and everything, uh, and add a sort of MR to revert initially, like just the like breaking part of the event, but still keeping the caching stuff. And I guess we have a lot of unit testing that that's pretty extensive and works well against the local version of the file, but we were not doing anything to make sure that that local version of file was reflective of what was upstream in the glue repository for snowplow. And so I've already started, uh, I've. I've made an MR or a log. I'll submit the MR after, but I've got the local changes right now to actually go and download the file in the MR pipeline. And so it will download the file from the glue registry. And then once it's done that, if there's any get difference between the file and what's there, it will, it will just spit out the diff saying, Hey, there's a difference in the file. We'll make sure that you update the local registry and commit the changes. And then after that, that will at least have our unit tests running against the correct schema. Okay. I think we needed to really move to using snowplow micro and CI so that we're testing that we're actually able to push the metrics up because our unit testing just validates that the ski like our Jason parsing works, not that the server will accept the Jason that we send up."
    },
    {
        "speaker": "SPEAKER_03",
        "start": 663.78,
        "end": 688.4,
        "text": "Yeah. So that was my question. I was like, I was actually surprised to learn that we have local copy. I didn't realize that was the case. And so it is the case then that we, there could be like, we don't have to have it. It's just, that's how it is. Right now. But we can, you mentioned using micro, which I don't know what that is, but it sounds like a snowplow thing. So we can sort of just pull, uh, we could pull the latest, like we don't, we wouldn't have to version the file in the language server anymore. Is that right? Or yeah."
    },
    {
        "speaker": "SPEAKER_01",
        "start": 688.62,
        "end": 764.56,
        "text": "Well, I know how to get points on a different thread that I've just thought of, uh, where right now we're doing an import to the file and it's committed into get, but instead of doing that, what we could do is we could keep the import the same way. And the import with ES bundle, we can actually download the file during build. Time to pull in the, the Jason schema. And so that could pull it from the actual registry and that way you had to be a build time failure if the file didn't exist in, and then we'd be using the file exactly as it was in the registry at build time, at least. So that's one way to go about it. But yeah, snowplow micro is running a snowplow, uh, locally. So whenever we're doing snowplow tracking, we can send it to our local registry instead of the GitLab, uh, server for the telemetry. And so when you're sending it to that local Docker container in the service, you can test things in a way that because the local snowplow micro will also pull the, from the production registry to check that all the metrics are good. And then still, I will do additional validation that you can't get. Um, so still plot Michael will actually give a list of like bad, bad events that it received. And so we can literally end the job, run our whole suite of integration tests. And if there's any bad events, we can err on the build and say, Hey, this bad event. Events was received by snowplow."
    },
    {
        "speaker": "SPEAKER_00",
        "start": 771.28,
        "end": 786.1,
        "text": "Is, uh, I was thinking like, is there a way to know that there is new schema published? Because, uh, I mean, like we, uh, we've done it manually, but we do not know, do not know when the new schema is published in this like equal repository. I'm not sure how it's called."
    },
    {
        "speaker": "SPEAKER_01",
        "start": 786.56,
        "end": 814.84,
        "text": "Yeah. So it's easy. So, yeah, I guess we can improve the way we're doing the poll, but right now it was a manual process to do the polling. I thought I've, I'm going to add our job, which will fail your MR. If there's been a change since the last time it's been merged domain, but the, yeah, we need, we need some way to push. Like if the new glue thing is there, get like do something we can maybe do a nightly job even where we run the lens job nightly. And if it fails on main, then we got to eat like an email that would even, that would be a small iteration. That'd be an improvement."
    },
    {
        "speaker": "SPEAKER_00",
        "start": 816.98,
        "end": 856.4,
        "text": "Yeah. Because like say we had now, like say, uh, this came up as updated, but it didn't get the. Version change. That's why we get this like difference, like where our local schema was the same version. That's like equal schema, but it was like had different like fields. I don't know, defined. Uh, so ideally this wouldn't happen. Uh, she shouldn't happen because they update those, the schema would mean a new schema filed. Right. And like, this is probably something that we need. Raza to track that like schema was updated there. Yeah. But yeah, I agree. It's like this manual thing is nice. It's not good."
    },
    {
        "speaker": "SPEAKER_04",
        "start": 862.94,
        "end": 879.08,
        "text": "So we need, we need to renovate for snow blow basically. Right. Cool. Um,"
    },
    {
        "speaker": "SPEAKER_03",
        "start": 879.12,
        "end": 918.88,
        "text": "maybe this is a moment also to broadcast the, by, by introducing the cash. The telemetry model has not changed, but we have. Basically two different we're introducing two different sources of suggestions. One source is the network, like the, you know, the, the usual one basically, and like the AI gateway. And the other one is the cash. So as far as the clients are concerned is like they request a suggestion. And then the language server decides whether it'll serve it from the cash or it'll serve it from, you know, fetching it in the server, but it should be transparent to clients, which is why we can actually. We use the current model telemetry model without making changes, which is quite neat. Um, yeah."
    },
    {
        "speaker": "SPEAKER_04",
        "start": 930.32,
        "end": 934.02,
        "text": "All right. There's some more activity in the doc now about, well,"
    },
    {
        "speaker": "SPEAKER_03",
        "start": 934.12,
        "end": 937.08,
        "text": "I don't know, Aaron having an epiphany maybe."
    },
    {
        "speaker": "SPEAKER_01",
        "start": 937.48,
        "end": 992.52,
        "text": "Yeah. You, you, you joked about having renovates for snowplow, but we could actually, that could literally solve the. The problem. Because what we would do is we just have, we just have a module that's available and that module would just build, we can have it where it like builds often or something like that, or it even like as a fork of the existing snowplow project. And essentially if, if there's an update there, it rebuilds a node module, which has the Json's available. And if that node module is updated, then it actually would trigger the regular renovate process. I think that would go in really like that would fit really well with our existing. What we do for dependencies in general, it like Matt sort of match that model, which would be good. So, but yes, I'm super happy about telemetry in general. I'm glad to see that we've pushed and come into an agreement. It was really active discussion. It's really good to see so many folks swarming around the sort of like, how do we get it to fit our existing model? Yeah."
    },
    {
        "speaker": "SPEAKER_03",
        "start": 992.9,
        "end": 1038.78,
        "text": "Cause like initially when I, it took me a while to find time to actually think this through. And then when I tried to think through, I was like, I can't, I can't figure this out. I feel like we need to change the model. Yeah. And then I talked with Shakur and he was like, yeah, I think we need to change the model or we need to just not have telemetry. Or we, we talked about a few options and then busty is basically kind of cracked that he was like, wait, the first, like the model is fine. Like don't change it. Just, and for me in my head, it's just, I was really like, yeah, requested loaded, like requested for me, man, just like a network request. There was no other way. Uh, it doesn't have to mean that though, but it was so, I don't know, branded in my head. I was just like, yeah, it doesn't work for one year to just a cash. How could this work? But actually it can work. It like. It's fine. It's just requested, you know, from the language server, um, which is, yeah. So this is cool."
    },
    {
        "speaker": "SPEAKER_04",
        "start": 1040.64,
        "end": 1041.2,
        "text": "All right."
    },
    {
        "speaker": "SPEAKER_03",
        "start": 1043.1000000000001,
        "end": 1068.1,
        "text": "And I also felt like, I felt like there must be a good solution to this, but couldn't find it. So I was happy that others were good. Yeah. All right. Um, yeah, there's nothing else in the notes doc, any other topics that people want to bring up and discuss? Definitely."
    }
]